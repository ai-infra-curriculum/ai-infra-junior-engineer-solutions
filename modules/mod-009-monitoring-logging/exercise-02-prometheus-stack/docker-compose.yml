version: '3.8'

# Prometheus Monitoring Stack for ML Infrastructure
# Includes: Prometheus, Alertmanager, Node Exporter, Custom Exporters

services:
  # ===========================
  # Prometheus Server
  # ===========================
  prometheus:
    image: prom/prometheus:v2.48.0
    container_name: prometheus
    hostname: prometheus
    restart: unless-stopped
    user: "65534"  # nobody user
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--storage.tsdb.retention.size=10GB'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
      - '--log.level=info'
    volumes:
      - ./config/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./config/prometheus/recording_rules.yml:/etc/prometheus/recording_rules.yml:ro
      - ./config/prometheus/alerting_rules.yml:/etc/prometheus/alerting_rules.yml:ro
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"
    networks:
      - monitoring
    depends_on:
      - alertmanager
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    labels:
      com.example.monitoring: "prometheus"
      com.example.team: "ml-platform"

  # ===========================
  # Alertmanager
  # ===========================
  alertmanager:
    image: prom/alertmanager:v0.26.0
    container_name: alertmanager
    hostname: alertmanager
    restart: unless-stopped
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
      - '--web.external-url=http://localhost:9093'
      - '--log.level=info'
    volumes:
      - ./config/alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
      - ./config/alertmanager/templates:/etc/alertmanager/templates:ro
      - alertmanager_data:/alertmanager
    ports:
      - "9093:9093"
    networks:
      - monitoring
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9093/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    labels:
      com.example.monitoring: "alertmanager"

  # ===========================
  # Node Exporter (Infrastructure Metrics)
  # ===========================
  node-exporter:
    image: prom/node-exporter:v1.7.0
    container_name: node-exporter
    hostname: node-exporter
    restart: unless-stopped
    command:
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - '--path.rootfs=/host/root'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
      - '--collector.netclass.ignored-devices=^(veth.*|br.*|docker.*|lo)$$'
      - '--collector.netdev.device-exclude=^(veth.*|br.*|docker.*|lo)$$'
      - '--no-collector.ipvs'
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/host/root:ro,rslave
    ports:
      - "9100:9100"
    networks:
      - monitoring
    pid: host
    labels:
      com.example.monitoring: "node-exporter"

  # ===========================
  # cAdvisor (Container Metrics)
  # ===========================
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.47.2
    container_name: cadvisor
    hostname: cadvisor
    restart: unless-stopped
    privileged: true
    devices:
      - /dev/kmsg
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    ports:
      - "8080:8080"
    networks:
      - monitoring
    command:
      - '--housekeeping_interval=10s'
      - '--docker_only=true'
      - '--disable_metrics=percpu,sched,tcp,udp,disk,diskIO,accelerator,hugetlb,referenced_memory,cpu_topology,resctrl'
    labels:
      com.example.monitoring: "cadvisor"

  # ===========================
  # ML Model Exporter (Custom Exporter)
  # ===========================
  ml-model-exporter:
    build:
      context: ./exporters/ml-model-exporter
      dockerfile: Dockerfile
    container_name: ml-model-exporter
    hostname: ml-model-exporter
    restart: unless-stopped
    environment:
      - EXPORTER_PORT=9101
      - MODEL_API_URL=http://inference-gateway:8000
      - SCRAPE_INTERVAL=15
      - LOG_LEVEL=info
    ports:
      - "9101:9101"
    networks:
      - monitoring
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9101/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    labels:
      com.example.monitoring: "ml-model-exporter"
      com.example.exporter.type: "custom"

  # ===========================
  # Pushgateway (Batch Job Metrics)
  # ===========================
  pushgateway:
    image: prom/pushgateway:v1.6.2
    container_name: pushgateway
    hostname: pushgateway
    restart: unless-stopped
    command:
      - '--web.listen-address=:9091'
      - '--persistence.file=/var/lib/pushgateway/metrics'
      - '--persistence.interval=5m'
    volumes:
      - pushgateway_data:/var/lib/pushgateway
    ports:
      - "9091:9091"
    networks:
      - monitoring
    labels:
      com.example.monitoring: "pushgateway"

  # ===========================
  # Blackbox Exporter (Endpoint Monitoring)
  # ===========================
  blackbox-exporter:
    image: prom/blackbox-exporter:v0.24.0
    container_name: blackbox-exporter
    hostname: blackbox-exporter
    restart: unless-stopped
    command:
      - '--config.file=/config/blackbox.yml'
    volumes:
      - ./config/exporters/blackbox.yml:/config/blackbox.yml:ro
    ports:
      - "9115:9115"
    networks:
      - monitoring
    labels:
      com.example.monitoring: "blackbox-exporter"

  # ===========================
  # Inference Gateway (from Exercise 01)
  # ===========================
  inference-gateway:
    image: inference-gateway:latest
    container_name: inference-gateway
    hostname: inference-gateway
    restart: unless-stopped
    environment:
      - SERVICE_NAME=inference-gateway
      - ENVIRONMENT=production
      - LOG_LEVEL=info
      - JAEGER_ENDPOINT=http://jaeger:4318/v1/traces
    ports:
      - "8000:8000"
    networks:
      - monitoring
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    labels:
      com.example.monitoring: "application"
      com.example.service: "inference-gateway"

# ===========================
# Networks
# ===========================
networks:
  monitoring:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

# ===========================
# Volumes
# ===========================
volumes:
  prometheus_data:
    driver: local
    driver_opts:
      type: none
      device: ${PWD}/data/prometheus
      o: bind
  alertmanager_data:
    driver: local
    driver_opts:
      type: none
      device: ${PWD}/data/alertmanager
      o: bind
  pushgateway_data:
    driver: local
