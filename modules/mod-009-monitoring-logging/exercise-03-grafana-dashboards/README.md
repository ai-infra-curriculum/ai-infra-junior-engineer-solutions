# Exercise 03: Grafana Dashboards - Complete Solution

## Overview

This is a **production-ready Grafana dashboard suite** for ML infrastructure monitoring, providing comprehensive visualization of SLOs, application performance, and infrastructure health. The solution builds upon Exercises 01-02 to transform raw Prometheus metrics into actionable insights.

## ğŸ¯ Solution Highlights

### Complete Dashboard Suite
- âœ… **SLO Overview Dashboard** - Real-time SLO compliance tracking
- âœ… **Application Performance Dashboard** - Request rates, latency, errors
- âœ… **Infrastructure Health Dashboard** - CPU, memory, network metrics
- âœ… **Programmatic Dashboard Generation** - Python script for maintainability
- âœ… **Multi-Data Source Integration** - Prometheus, Loki, Jaeger

### Advanced Features
- âœ… **Dashboard-as-Code** - Version-controlled JSON configurations
- âœ… **Automatic Provisioning** - Data sources and dashboards auto-configured
- âœ… **Trace-Metrics-Logs Correlation** - Unified observability
- âœ… **Responsive Design** - Optimized for different screen sizes
- âœ… **Custom Time Ranges** - Flexible time window selection

## ğŸ“ Project Structure

```
exercise-03-grafana-dashboards/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ grafana/
â”‚   â”‚   â””â”€â”€ provisioning/
â”‚   â”‚       â”œâ”€â”€ datasources/
â”‚   â”‚       â”‚   â””â”€â”€ datasources.yml          # Prometheus, Loki, Jaeger configs
â”‚   â”‚       â”œâ”€â”€ dashboards/
â”‚   â”‚       â”‚   â””â”€â”€ dashboards.yml           # Dashboard provisioning config
â”‚   â”‚       â”œâ”€â”€ alerting/                    # Grafana unified alerting
â”‚   â”‚       â””â”€â”€ notifiers/                   # Notification channels
â”‚   â””â”€â”€ dashboards/
â”‚       â”œâ”€â”€ ml-platform/
â”‚       â”‚   â”œâ”€â”€ slo-overview.json            # SLO tracking dashboard
â”‚       â”‚   â””â”€â”€ application-performance.json  # App metrics dashboard
â”‚       â”œâ”€â”€ infrastructure/
â”‚       â”‚   â””â”€â”€ infrastructure-health.json    # Infrastructure dashboard
â”‚       â”œâ”€â”€ executive/                        # Executive summary dashboards
â”‚       â””â”€â”€ default/                          # Home dashboards
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ generate-dashboards.py               # Dashboard generator (Python)
â”‚   â””â”€â”€ setup.sh                             # Environment setup script
â”œâ”€â”€ docker-compose.yml                       # Full stack with Grafana
â”œâ”€â”€ .env.example                             # Environment configuration template
â””â”€â”€ README.md                                # This file
```

## ğŸš€ Quick Start

### Prerequisites

- Docker and Docker Compose installed
- Exercises 01-02 completed (or Exercise 02 Prometheus stack running)
- Python 3.7+ (for dashboard generation)

### 1. Setup

```bash
# Run setup script
./scripts/setup.sh

# Edit .env file
cp .env.example .env
nano .env

# Set admin credentials and SMTP settings if needed
```

### 2. Start the Stack

```bash
# Start all services (Grafana, Prometheus, Loki, Jaeger)
docker-compose up -d

# Check service health
docker-compose ps

# View Grafana logs
docker-compose logs -f grafana
```

### 3. Access Grafana

```bash
# Open in browser
open http://localhost:3000

# Default login
# Username: admin
# Password: admin
# (Change password on first login)
```

### 4. Explore Dashboards

Navigate to **Dashboards â†’ Browse** and explore:

1. **ML Platform** folder:
   - SLO Overview
   - Application Performance

2. **Infrastructure** folder:
   - Infrastructure Health

## ğŸ“Š Dashboard Details

### 1. SLO Overview Dashboard

**Purpose**: Real-time SLO compliance tracking for on-call engineers

**Panels**:
- **Availability SLO (30d)** - Gauge showing current 30-day availability vs 99.5% target
- **Latency P99 (7d)** - Gauge showing P99 latency vs 300ms target
- **Error Budget Remaining** - Percentage of monthly error budget left
- **Burn Rate (1h)** - Current error budget consumption rate
- **Availability Trends** - Time series of 5-minute availability percentages
- **Error Budget Consumption** - Burn rates across 1h, 6h, and 3d windows
- **Latency Percentiles** - P50, P95, P99 latency over time

**Use Cases**:
- Monitor SLO compliance during incidents
- Track error budget consumption
- Identify availability and latency degradation trends
- Determine if deployments impact SLOs

**Screenshot Equivalent**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SLO Overview - ML Inference Platform              Last 6h  â–¼   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Availabilityâ”‚  Latency P99â”‚ Error Budgetâ”‚    Burn Rate (1h)   â”‚
â”‚             â”‚             â”‚             â”‚                     â”‚
â”‚   99.87%    â”‚   245 ms    â”‚   76.2%     â”‚       2.1x          â”‚
â”‚   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    â”‚   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    â”‚   â–ˆâ–ˆâ–ˆâ–ˆ      â”‚       Low           â”‚
â”‚   Target:   â”‚   Target:   â”‚   Status:   â”‚    Fast: 14.4x      â”‚
â”‚   99.5%     â”‚   < 300ms   â”‚   Healthy   â”‚    Slow: 6.0x       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. Application Performance Dashboard

**Purpose**: Monitor inference gateway request metrics and errors

**Panels**:
- **Request Rate (QPS)** - Queries per second
- **Error Rate** - Percentage of failed requests
- **Avg Response Time** - Mean latency in milliseconds
- **Active Requests** - Current in-flight requests
- **Request Rate by Endpoint** - Traffic breakdown by API endpoint
- **Error Rate Over Time** - 5xx errors by status code

**Use Cases**:
- Diagnose traffic spikes or drops
- Identify high-error endpoints
- Track latency degradation
- Monitor system saturation

### 3. Infrastructure Health Dashboard

**Purpose**: Monitor container and host resource utilization

**Panels**:
- **CPU Usage by Container** - CPU percentage per service
- **Memory Usage by Container** - Memory percentage per service
- **Network Receive Rate** - Inbound network traffic (MB/s)
- **Network Transmit Rate** - Outbound network traffic (MB/s)

**Use Cases**:
- Identify resource-constrained services
- Detect memory leaks
- Monitor network saturation
- Plan capacity upgrades

## ğŸ”§ Operations

### Regenerating Dashboards

```bash
# Edit dashboard generator
nano scripts/generate-dashboards.py

# Regenerate dashboard JSON files
python3 scripts/generate-dashboards.py

# Restart Grafana to reload
docker-compose restart grafana
```

### Adding Custom Dashboards

```python
# In scripts/generate-dashboards.py, add a new function:

def create_custom_dashboard():
    db = DashboardBuilder(
        title="My Custom Dashboard",
        uid="custom-dashboard",
        tags=["Custom"]
    )

    db.add_stat_panel(
        title="My Metric",
        query="my_custom_metric",
        unit="short",
        x=0, y=0, w=6, h=4
    )

    return db.to_json()

# Add to main() function:
dashboards = {
    # ... existing dashboards
    "default/custom-dashboard.json": create_custom_dashboard(),
}
```

### Checking Data Sources

```bash
# Via API
curl -u admin:admin http://localhost:3000/api/datasources | jq .

# Test Prometheus connection
curl -u admin:admin http://localhost:3000/api/datasources/proxy/1/api/v1/query?query=up | jq .
```

### Exporting Dashboards

```bash
# Export dashboard JSON via API
DASHBOARD_UID="slo-overview"
curl -u admin:admin "http://localhost:3000/api/dashboards/uid/${DASHBOARD_UID}" | jq .dashboard > exported-dashboard.json
```

### Importing Dashboards

```bash
# Via UI: Dashboards â†’ Import â†’ Upload JSON file

# Via API:
curl -X POST -H "Content-Type: application/json" \
  -u admin:admin \
  -d @dashboard.json \
  http://localhost:3000/api/dashboards/db
```

## ğŸ“ˆ PromQL Queries Used

### SLO Queries

```promql
# Availability (30-day)
slo:availability:ratio_rate30d

# Latency P99 (7-day)
slo:http_request_duration:p99:rate7d

# Error budget remaining
slo:availability:error_budget_remaining * 100

# Burn rate (1h)
slo:availability:burn_rate:1h
```

### Application Queries

```promql
# Request rate
sum(rate(http_requests_total{service="inference-gateway"}[5m]))

# Error rate percentage
sum(rate(http_requests_total{service="inference-gateway",status=~"5.."}[5m]))
/
sum(rate(http_requests_total{service="inference-gateway"}[5m]))
* 100

# Average latency
sum(rate(http_request_duration_seconds_sum{service="inference-gateway"}[5m]))
/
sum(rate(http_request_duration_seconds_count{service="inference-gateway"}[5m]))
* 1000
```

### Infrastructure Queries

```promql
# CPU usage by container
container:cpu_usage:percent

# Memory usage by container
container:memory_usage:percent

# Network receive rate
container:network_receive:rate5m_mb

# Network transmit rate
container:network_transmit:rate5m_mb
```

## ğŸ—ï¸ Architecture

### Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Data Sources                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ Prometheus â”‚  â”‚    Loki    â”‚  â”‚   Jaeger   â”‚          â”‚
â”‚  â”‚  :9090     â”‚  â”‚   :3100    â”‚  â”‚  :16686    â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜          â”‚
â”‚         â”‚                â”‚                â”‚               â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                          â”‚ Queries                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚      Grafana        â”‚
                â”‚                     â”‚
                â”‚  - Dashboard Engine â”‚
                â”‚  - Query Processor  â”‚
                â”‚  - Data Aggregation â”‚
                â”‚  - Visualization    â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚ HTTP (Port 3000)
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚   Web Browser   â”‚
                  â”‚   (Dashboard)   â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Responsibilities

| Component | Purpose | Port |
|-----------|---------|------|
| Grafana | Dashboard visualization and queries | 3000 |
| Prometheus | Metrics data source | 9090 |
| Loki | Logs data source | 3100 |
| Jaeger | Traces data source | 16686 |

## ğŸ¨ Dashboard Design Principles

### Best Practices Implemented

1. **Golden Signals First** - Latency, traffic, errors, saturation prominently displayed
2. **SLO-Driven** - Dashboards focused on what matters for reliability
3. **Actionable** - Each panel enables specific operational decisions
4. **Consistent Layout** - Stats at top, graphs below, critical metrics left-to-right
5. **Appropriate Visualization** - Gauges for current state, time series for trends
6. **Color-Blind Friendly** - Uses shapes and thresholds, not just colors

### Panel Types Used

- **Stat Panels**: Single values with thresholds (QPS, error rate, budget)
- **Gauge Panels**: Progress toward goals (SLO compliance, resource usage)
- **Time Series**: Trends over time (latency, availability, traffic)
- **Rows**: Collapsible sections for organization

## ğŸ”— Integration Points

### With Exercise 01 (Observability Foundations)
- Visualizes Four Golden Signals metrics
- Displays SLIs defined in Exercise 01
- Queries exposed `/metrics` endpoint

### With Exercise 02 (Prometheus Stack)
- Uses recording rules for fast queries
- Displays alert state from Alertmanager
- Leverages service discovery labels

### With Exercise 04 (Logging Pipeline)
- Loki data source pre-configured
- Trace ID drill-down to logs
- Log panel templates ready

### With Exercise 05 (Incident Response)
- Dashboards linked from alert annotations
- Incident timeline overlays
- Root cause analysis views

## ğŸ“š Learning Outcomes

This solution demonstrates:

âœ… **Grafana Deployment** - Production configuration with Docker
âœ… **Data Source Configuration** - Multi-source integration (Prometheus, Loki, Jaeger)
âœ… **Dashboard Design** - UX best practices and visualization theory
âœ… **Dashboard-as-Code** - Programmatic generation with Python
âœ… **Provisioning** - Automatic configuration on startup
âœ… **PromQL Mastery** - Complex queries for SLO tracking
âœ… **Correlation** - Metrics, logs, and traces linked
âœ… **Operational Dashboards** - Role-specific views (on-call, ops, exec)

## ğŸ“ Advanced Topics

### Custom Panel Plugins

```bash
# Install custom panel plugins
docker-compose exec grafana grafana-cli plugins install grafana-piechart-panel
docker-compose restart grafana
```

### Dashboard Variables

Add dynamic filtering with template variables:

```python
db.add_variable(
    name="service",
    query='label_values(up, service)',
    label="Service",
    all_value=True
)
```

Use in queries:
```promql
up{service="$service"}
```

### Annotations

Display deployment events on dashboards via annotations API:

```bash
curl -X POST http://localhost:3000/api/annotations \
  -H "Content-Type: application/json" \
  -u admin:admin \
  -d '{
    "dashboardUID": "slo-overview",
    "time": '$(date +%s)'000,
    "text": "Deployment v1.2.3",
    "tags": ["deployment"]
  }'
```

## ğŸ‰ Success Criteria

- âœ… Grafana accessible at http://localhost:3000
- âœ… All 3 data sources (Prometheus, Loki, Jaeger) healthy
- âœ… 3 dashboards auto-loaded and functional
- âœ… SLO metrics displaying correctly
- âœ… Drill-down from metrics to traces working
- âœ… Dashboards regenerable via Python script

---

**ğŸ“ Ready for Exercise 04: Logging Pipeline!**
